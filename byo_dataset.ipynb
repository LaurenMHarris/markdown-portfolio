{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/LaurenMHarris/markdown-portfolio/blob/main/byo_dataset.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "508f2b28-54c0-4ba4-8714-5c68cb9fef75",
      "metadata": {
        "id": "508f2b28-54c0-4ba4-8714-5c68cb9fef75"
      },
      "source": [
        "# Women Who Code :: Build-Your-Own Dataset\n",
        "\n",
        "Sometimes data scientists are handed a fully prepared and cleaned dataset, but this is rarely the case. Today's workshop will give you practice in building your own dataset from scratch. We will use public APIs and publically available data files to create a dataset of weather and population data that is ready for downstream uses.\n",
        "\n",
        "In this workshop, we'll be collecting and organizing information for fictional visitors to a fictional website.\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# clone the git repo\n",
        "!git clone https://github.com/kaylarobinson077/shareouts.git\n",
        "\n",
        "# navigate to the women who code directory\n",
        "%cd shareouts/womenwhocode/\n",
        "# install requirements\n",
        "!pip install -r requirements.in --quiet"
      ],
      "metadata": {
        "id": "Z9tWvmHksj2Z",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "33ee6eae-72e2-4604-c53b-b35ced29bd9e"
      },
      "id": "Z9tWvmHksj2Z",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'shareouts'...\n",
            "remote: Enumerating objects: 63, done.\u001b[K\n",
            "remote: Counting objects: 100% (63/63), done.\u001b[K\n",
            "remote: Compressing objects: 100% (36/36), done.\u001b[K\n",
            "remote: Total 63 (delta 24), reused 57 (delta 22), pack-reused 0\u001b[K\n",
            "Unpacking objects: 100% (63/63), done.\n",
            "/content/shareouts/womenwhocode\n",
            "\u001b[K     |████████████████████████████████| 1.5 MB 5.3 MB/s \n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "22e1bcd5",
      "metadata": {
        "id": "22e1bcd5"
      },
      "outputs": [],
      "source": [
        "# If you have installed the requirements in the requirements.txt file,\n",
        "# you will have the packages needed here\n",
        "from faker import Faker  # This helps with creating fake data, more details below!\n",
        "import pandas as pd\n",
        "import requests"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ea680bb3-783a-4a3f-aa4c-9cb6403f91fb",
      "metadata": {
        "id": "ea680bb3-783a-4a3f-aa4c-9cb6403f91fb"
      },
      "source": [
        "# Part 1 :: Calling Public APIs\n",
        "\n",
        "In this first section we will use several publically available APIs to collect information about fictional visitors to our website. The only information we directly collect about visitors is their IP address. Beyond that, we'll have to look to outside sources to pull in information to learn more about our visitors."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "51372b8f",
      "metadata": {
        "id": "51372b8f"
      },
      "source": [
        "## Get your IP address\n",
        "\n",
        "An IP address is a unique address that identifies a device on the internet or a local network. IP stands for \"Internet Protocol,\" which is the set of rules governing the format of data sent via the internet or local network.\n",
        "\n",
        "To find out your own IP address, you can make a call to the [ipify](https://www.ipify.org/) API, a simple public IP address API. This API does not require an account or API key."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "26538a01",
      "metadata": {
        "id": "26538a01",
        "cellView": "code"
      },
      "outputs": [],
      "source": [
        "# api endpoint\n",
        "url = \"https://api.ipify.org\""
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# TODO - call the api, and save the response to a variable called `resp`"
      ],
      "metadata": {
        "id": "GfAK3ARyu1_c"
      },
      "id": "GfAK3ARyu1_c",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "1bd88f6d-8c4d-48ed-a142-858f78bfabec",
      "metadata": {
        "id": "1bd88f6d-8c4d-48ed-a142-858f78bfabec"
      },
      "source": [
        "Congrats, you just made a call to the first API of this workshop! Let's take a closer look at the response, and see what information we've collected from it."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c753b0ad-5074-4efa-8f66-a21822dd5f7d",
      "metadata": {
        "id": "c753b0ad-5074-4efa-8f66-a21822dd5f7d"
      },
      "outputs": [],
      "source": [
        "# http response status codes indicate whether the request has been successfully completed\n",
        "# Here is one place you can learn more about these status codes: https://en.wikipedia.org/wiki/List_of_HTTP_status_codes\n",
        "\n",
        "# TODO - print the response code"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fa6cd471",
      "metadata": {
        "id": "fa6cd471"
      },
      "outputs": [],
      "source": [
        "# can get response in a string format\n",
        "\n",
        "# TODO - print the response in a string format"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c38e3e58",
      "metadata": {
        "id": "c38e3e58"
      },
      "outputs": [],
      "source": [
        "# or more usefully as a json dictionary\n",
        "\n",
        "# TODO - print the response in json format"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "785d95aa",
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "785d95aa"
      },
      "outputs": [],
      "source": [
        "# That makes it dictionary, making it easier to pull out values like the ip address\n",
        "\n",
        "# TODO - print the datatype after reading the response as json"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ab087789",
      "metadata": {
        "id": "ab087789"
      },
      "outputs": [],
      "source": [
        "# let's hold on to ip address, and use it in some next steps\n",
        "\n",
        "# TODO - create a variable called `ip` that contains the IP address value as a string"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "bdb49d44",
      "metadata": {
        "tags": [],
        "id": "bdb49d44"
      },
      "source": [
        "## Get location for an IP address\n",
        "\n",
        "IP addresses can be linked to information about the location where you are connected to the internet.\n",
        "\n",
        "To find geolocation information given an IP address, we can use the [ip-api](https://ip-api.com/) JSON endpoint. The IP address endpoint allowed us to pass the desired response format (JSON) as a query parameter, but this API has a specific JSON endpoint, so we'll specify the data format as part of the URL."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "98a46c4f",
      "metadata": {
        "id": "98a46c4f"
      },
      "outputs": [],
      "source": [
        "url = f\"http://ip-api.com/json/{ip}\""
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# TODO - call the api, and save the response to a variable called `resp`"
      ],
      "metadata": {
        "id": "d0tVKHBowi1f"
      },
      "id": "d0tVKHBowi1f",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bb23de38",
      "metadata": {
        "id": "bb23de38"
      },
      "outputs": [],
      "source": [
        "# check that the call succeeded\n",
        "\n",
        "# TODO - print the status code"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "97ca433c",
      "metadata": {
        "id": "97ca433c"
      },
      "outputs": [],
      "source": [
        "# inspect the returned data\n",
        "\n",
        "# TODO - print the contents of response as json"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b33a9cbe",
      "metadata": {
        "id": "b33a9cbe"
      },
      "outputs": [],
      "source": [
        "# pull out the lat/long fields, since we can look up info about this location\n",
        "\n",
        "# TODO - create a variable `lat` and `lon` which each store the latitude and\n",
        "# longitude from the response, respectively."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "be34325a",
      "metadata": {
        "id": "be34325a"
      },
      "outputs": [],
      "source": [
        "# to easily repeat this call, put the steps we just took into a function\n",
        "\n",
        "def get_location_info(ip: str):\n",
        "    \"\"\"\n",
        "    Given an IP address, return a dictionary of location information.\n",
        "    \"\"\"\n",
        "    url = f\"http://ip-api.com/json/{ip}\"\n",
        "    \n",
        "    # TODO - call the api and return its json response"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d20fdd2b",
      "metadata": {
        "id": "d20fdd2b"
      },
      "source": [
        "## Get the local weather\n",
        "\n",
        "Now that we know where a visitor is from, we can collect any information from other sources to learn more about that location. For this workshop, let's suppose that the visitor's current weather is of interest to us.\n",
        "\n",
        "Given the visitor's latitude and longitude, we can use the [Open Meteo](https://open-meteo.com/en) API to get information about the location's current weather. Like the other APIs we've used in this workshop, Open Meteo is public and does not require an API key.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0bcebdcb",
      "metadata": {
        "id": "0bcebdcb"
      },
      "outputs": [],
      "source": [
        "# api endpoint\n",
        "url = \"https://api.open-meteo.com/v1/forecast\"\n",
        "\n",
        "# dictionary of the values we need to pass in our request\n",
        "params = {\"latitude\": lat, \"longitude\": lon, \"current_weather\": True, \"format\": \"json\"}"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# TODO - call the api, and save the response to a variable called `resp`"
      ],
      "metadata": {
        "id": "YR64zGGJxSsU"
      },
      "id": "YR64zGGJxSsU",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e9f686fa",
      "metadata": {
        "id": "e9f686fa"
      },
      "outputs": [],
      "source": [
        "# TODO - print the response status code"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ff5e7806",
      "metadata": {
        "id": "ff5e7806"
      },
      "outputs": [],
      "source": [
        "# TODO - print the response contents as json"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "252c0a44",
      "metadata": {
        "id": "252c0a44"
      },
      "outputs": [],
      "source": [
        "# to reproduce these steps, put them into a function\n",
        "def get_weather_info(lat: float, long: float):\n",
        "    \"\"\"\n",
        "    Given a latitude and longitude, return the current weather.\n",
        "    \"\"\"\n",
        "    url = \"https://api.open-meteo.com/v1/forecast\"\n",
        "\n",
        "    params = {\n",
        "        \"latitude\": lat,\n",
        "        \"longitude\": long,\n",
        "        \"current_weather\": True,\n",
        "        \"format\": \"json\",\n",
        "    }\n",
        "\n",
        "    # TODO - call the api and return its json response"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a3e58ea3",
      "metadata": {
        "id": "a3e58ea3"
      },
      "source": [
        "# Part 2 :: Prepare Your Dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d5184b0c",
      "metadata": {
        "id": "d5184b0c"
      },
      "source": [
        "## 2.1 :: Generate fake IP addresses\n",
        "\n",
        "Since we are working with fake data, we'll have to create some fake IP addresses for our website visitors. To do this, we'll use a package called [Faker](https://faker.readthedocs.io/en/master/) which generates fake data. It can generate all types of fake data, ranging from addresses to names to, wouldn't you know it, ID addresses!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5910533b",
      "metadata": {
        "id": "5910533b"
      },
      "outputs": [],
      "source": [
        "# TODO - use faker to generate a fake ip address"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a3d4cc32",
      "metadata": {
        "id": "a3d4cc32"
      },
      "source": [
        "## 2.2 :: Generate weather data\n",
        "\n",
        "For each visitor IP address, we'll want to run our full weather collection process of getting location based on IP, then weather based on location. One way to do this is to define a function that takes in a (fake) IP address, hits the IP-to-location API, then sends this response to the Location-to-weather API."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "62ff0cfe",
      "metadata": {
        "id": "62ff0cfe"
      },
      "outputs": [],
      "source": [
        "def get_geo_weather_data(ip: str):\n",
        "    \"\"\"Pull weather data for given ip address\"\"\"\n",
        "    # TODO - get location info for the ip address using the function we defined\n",
        "\n",
        "    # TODO - get the current weather at the lat/long using the function we defined\n",
        "\n",
        "    # TODO - stack the dictionaries\n",
        "\n",
        "    # TODO - return the resulting stacked dictionaries"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7acb83de",
      "metadata": {
        "id": "7acb83de"
      },
      "source": [
        "By organizing all of the API calls into a single function, this allows us to write a simple function that:\n",
        "\n",
        "1. Makes a fake IP address\n",
        "2. Gets the location and weather data for that IP adress\n",
        "3. Handles the case where we don't get back valid weather data (for example, an API returned an error)\n",
        "\n",
        "Notice that we have set a parameter called `max_retries`, "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "de5b8682",
      "metadata": {
        "id": "de5b8682"
      },
      "outputs": [],
      "source": [
        "def get_fake_geo_weather_data(max_retries=5):\n",
        "    \"\"\"Pull weather data for fake ip address, up to the given number of retries\"\"\"\n",
        "    # keep trying again until we either get a valid result, or hit the max number of retries\n",
        "    retries = 0\n",
        "    faker = Faker()\n",
        "    while retries <= max_retries:\n",
        "        fake_ip = faker.ipv4()\n",
        "        # we won't always get successful results from each IP\n",
        "        try:\n",
        "            return get_geo_weather_data(fake_ip)\n",
        "        # for now, we can skip any failed attempts\n",
        "        except:\n",
        "            retries += 1\n",
        "    print(\"Max retries reached!\")\n",
        "    return None"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d7fa9b7b",
      "metadata": {
        "id": "d7fa9b7b"
      },
      "source": [
        "To handle potential API errors, we allowed our function to return a value of `None` in cases where no valid data was returned after the maximum number of retries. To clean up the data and make it easier for analysis, we can drop these failed attempts from our list of weather data responses."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9821abfe-e94f-4d49-9ffa-50b6194dcb46",
      "metadata": {
        "id": "9821abfe-e94f-4d49-9ffa-50b6194dcb46"
      },
      "outputs": [],
      "source": [
        "# TODO - use the above function to create a list of data"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "054b53b0",
      "metadata": {
        "id": "054b53b0"
      },
      "source": [
        "Pandas dataframes are a standard across many data science teams, and so we will convert this list of dicts to a DataFrame for downstream analysis and data validation."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e14281a9-0176-40e6-b21b-0fc8ab59e4e6",
      "metadata": {
        "id": "e14281a9-0176-40e6-b21b-0fc8ab59e4e6"
      },
      "outputs": [],
      "source": [
        "# list of dicts to pandas dataframe is easy!\n",
        "\n",
        "# TODO - convert the list to a pandas dataframe"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ac3fff54-e45f-4a67-9162-df28ae480544",
      "metadata": {
        "id": "ac3fff54-e45f-4a67-9162-df28ae480544"
      },
      "outputs": [],
      "source": [
        "# take a peek to make sure the data looks as we'd expect it to\n",
        "\n",
        "# TODO - print the first few rows of the dataframe"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "58732a75-2522-44f7-b698-c21b8f2fbcfb",
      "metadata": {
        "id": "58732a75-2522-44f7-b698-c21b8f2fbcfb"
      },
      "outputs": [],
      "source": [
        "# pandas made it easy to inspect our data, such as seeing the set of countries we collected data from\n",
        "\n",
        "# TODO - print a list of the unique countries in the dataframe"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6a1b9c4e",
      "metadata": {
        "id": "6a1b9c4e"
      },
      "source": [
        "And there you have it! At this point, we have used several public APIs to collect location and weather data about imaginary visitors to our company's website. We've organized this data into a Pandas DataFrame format, which will make it easy to combine with additional data, and to use for downstream analysis or modeling applications."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "fdd8def6-10fb-4898-9b5f-4d50e212155b",
      "metadata": {
        "id": "fdd8def6-10fb-4898-9b5f-4d50e212155b"
      },
      "source": [
        "## 2.3 :: Join with Migration Data\n",
        "\n",
        "We learned a lot about our individual visitors by inspecting their IP address, and calling other APIs to collect supplemental information off of this.\n",
        "\n",
        "Often times, relevant data might exist in a database or table format. For example, consider the case where our website may be offering relocation services, such as a moving company or a service that helps individuals find job opportunities in new countries. For a use-case like this, it could be valuable to learn about the typical migration rates in and out of the countries in which our visitors reside.\n",
        "\n",
        "Luckily for us, the United Nations publishes migration rates at the country level publically, and we can download this data for free. After accessing this data, we can join it to our visitors data table using a key of \"Country\".\n",
        "\n",
        "XLSX file available from the UN:\n",
        "\n",
        "https://population.un.org/wpp/Download/Standard/Migration/\n",
        "\n",
        "In case the location of this file changes, we've also attached a copy of it to this Repo."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cec2a285",
      "metadata": {
        "id": "cec2a285"
      },
      "outputs": [],
      "source": [
        "# skip the first few rows, which just contain extra header information\n",
        "df_migration = pd.read_excel(\n",
        "    \"https://population.un.org/wpp/Download/Files/1_Indicators%20(Standard)/EXCEL_FILES/4_Migration/WPP2019_MIGR_F01_NET_MIGRATION_RATE.xlsx\",\n",
        "    skiprows=range(16),\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "65ff52a5-586d-461c-af18-8800d3d42ad5",
      "metadata": {
        "id": "65ff52a5-586d-461c-af18-8800d3d42ad5"
      },
      "outputs": [],
      "source": [
        "# TODO - print the first few rows of this data table"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "411030d5",
      "metadata": {
        "id": "411030d5"
      },
      "outputs": [],
      "source": [
        "# TODO - print the unique values in the `Type` column"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "825ac07d",
      "metadata": {
        "id": "825ac07d"
      },
      "source": [
        "Looking at the data as it's read in, you can make several observations:\n",
        "\n",
        "- Data is reported at various aggregations, such as country, income, overall (world), etc.\n",
        "- Metrics are reported at various date ranges. While interesting to have, we are likely going to be most interested in the most recent year range (2015-2020)\n",
        "\n",
        "Because of our specific interests, let's limit rows to just those reporting on country-level values, and limit columns to just the region name and most recent measurement."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "63274163-b149-4add-8cb0-113b6eea9d38",
      "metadata": {
        "id": "63274163-b149-4add-8cb0-113b6eea9d38"
      },
      "outputs": [],
      "source": [
        "# limit to only country-level rows\n",
        "\n",
        "# TODO - limit the migration dataframe to only entries with type of `Country/Area`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3c1ce3dd-7a9f-4c4d-9756-869887ad6af5",
      "metadata": {
        "id": "3c1ce3dd-7a9f-4c4d-9756-869887ad6af5"
      },
      "outputs": [],
      "source": [
        "# limit to only relevant columns\n",
        "\n",
        "# TODO - limit the migration dataframe to only include the columns\n",
        "# \"Region, subregion, country or area *\", and \"2015-2020\""
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5af5abc3",
      "metadata": {
        "id": "5af5abc3"
      },
      "source": [
        "Right now, the column names aren't very specific to our limited use case. So, we can rename the columns in our subsetted dataframe to be more interpretable in our downstream dataset. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2ab7ea82-1f27-474f-bea4-e01ee9ca3253",
      "metadata": {
        "id": "2ab7ea82-1f27-474f-bea4-e01ee9ca3253"
      },
      "outputs": [],
      "source": [
        "# TODO - rename columns of the migration dataframe to be easier to work with"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0ae7439f",
      "metadata": {
        "id": "0ae7439f"
      },
      "source": [
        "At this point, we have a cleaned up DataFrame with weather data (at the visitor-level), and a cleaned up DataFrame with migration data (at the country-level). To be able to look at these metrics together, we will join the data together. Because our ultimate goal is to have all data at the website visitor level, we will want to perform a left join of the migration data to the weather data, as the migration data is aggregated at a coarser level."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6d930f4d-edcb-499f-b9dd-8c3c1bfaa4cc",
      "metadata": {
        "id": "6d930f4d-edcb-499f-b9dd-8c3c1bfaa4cc"
      },
      "outputs": [],
      "source": [
        "# TODO - left join migration data onto weather data, using the column 'country' as the key"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ff97128b",
      "metadata": {
        "id": "ff97128b"
      },
      "source": [
        "And, voila!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d0cd2024-c049-4bd1-b9c4-6292488f1d8e",
      "metadata": {
        "id": "d0cd2024-c049-4bd1-b9c4-6292488f1d8e"
      },
      "outputs": [],
      "source": [
        "# TODO - print the first few rows of the resulting dataframe"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8f6b741c",
      "metadata": {
        "id": "8f6b741c"
      },
      "source": [
        "## 2.4 :: Data Validation and Cleaning\n",
        "\n",
        "So far things are looking pretty good, but let's dig a little bit deeper to see how things turned out after the join. One thing to be cautious about here is that our left join will still return a result if there are cases where there may not have been a match. For example, if a particualr visitor's country doesn't have a perfect match in the migration dataset, it will remain a row in our dataframe, but all of the weather and location data will be left empty!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "83208806-2741-4273-bc9d-95e3708cfbac",
      "metadata": {
        "id": "83208806-2741-4273-bc9d-95e3708cfbac"
      },
      "outputs": [],
      "source": [
        "# TODO - print the list of countries that have a non-null migration rate\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ceea5be5-1a7d-4e0c-9e2c-4079a5b2d8d9",
      "metadata": {
        "id": "ceea5be5-1a7d-4e0c-9e2c-4079a5b2d8d9"
      },
      "outputs": [],
      "source": [
        "# TODO - print the list of countries that have a null migration rate"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "68c91edb",
      "metadata": {
        "id": "68c91edb"
      },
      "source": [
        "Based on the findings of the above cell (listing out the contries where migration rate is empty) we can see a list of countries that don't have an exact string match to the migration data. To help troubleshoot this, we can search the migration data for entries that contain at least a partial string match."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "51b211bb-6e9e-433b-891b-2e157b122fad",
      "metadata": {
        "id": "51b211bb-6e9e-433b-891b-2e157b122fad"
      },
      "outputs": [],
      "source": [
        "# search for strings containing `United States`\n",
        "# this shows that the migration data refers to this country as `United States of America`\n",
        "# we can clean this up prior to the join, and then they should match up\n",
        "\n",
        "# TODO - print rows from the migration dataset containing the substring `United States`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f63d1570-90be-42c9-927e-8530c1f07904",
      "metadata": {
        "id": "f63d1570-90be-42c9-927e-8530c1f07904"
      },
      "outputs": [],
      "source": [
        "# to get join to work, let's rename country in the migration dataset\n",
        "# this dict of replacements came from running a number of IPs through our process\n",
        "# it may not be exhaustive\n",
        "\n",
        "# TODO - replace country names in the migration subset to match with the weather dataset\n",
        "\n",
        "# use ths dict to start, though we may have to add to it\n",
        "to_replace={\n",
        "    \"United States of America\": \"United States\",\n",
        "    \"Syrian Arab Republic\": \"Syria\",\n",
        "    \"Russian Federation\": \"Russia\",\n",
        "    \"Republic of Korea\": \"South Korea\",\n",
        "    \"Venezuela (Bolivarian Republic of)\": \"Venezuela\",\n",
        "    \"Viet Nam\": \"Vietnam\",\n",
        "    \"China, Taiwan Province of China\": \"Taiwan\",\n",
        "}\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e005ad15-aa31-4025-a69e-e994cc8b7430",
      "metadata": {
        "id": "e005ad15-aa31-4025-a69e-e994cc8b7430"
      },
      "outputs": [],
      "source": [
        "# try the join again\n",
        "\n",
        "# TODO - repeat the merge, but with the updated migration data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2660c6c3-d189-452d-9c42-df477e45d912",
      "metadata": {
        "id": "2660c6c3-d189-452d-9c42-df477e45d912"
      },
      "outputs": [],
      "source": [
        "# now see if all entries have a match\n",
        "# empty array means that no entries are missing migration data\n",
        "\n",
        "# TODO - check for empty values, to see if we caught all missing values"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "02cfb0e6",
      "metadata": {
        "id": "02cfb0e6"
      },
      "source": [
        "At this point, we've created a dataset containing location, weather, and migration data for visitors to our website. Depending on your use-case, at this point you may decide to add in additional data sources, perform feature engineering, or implement extra cleanup and data validation steps."
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "wwc",
      "language": "python",
      "name": "wwc"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.7"
    },
    "colab": {
      "name": "byo_dataset.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}